# The FROM instruction specifies the base model to use. This is a required field.
# Replace 'model-name:tag' with the model you want to start with (e.g., llama3:latest).
FROM hf.co/unsloth/Jan-nano-128k-GGUF:Q4_K_XL

# The PARAMETER instruction sets a runtime parameter for the model.
# You can have multiple PARAMETER lines.
# Example: sets the creativity. Higher is more creative, lower is more coherent.
PARAMETER temperature 0.8
# Example: sets the context window size (how much text the model remembers).
PARAMETER num_predict 8096
PARAMETER top_k 30
PARAMETER top_p 0.90
PARAMETER num_gpu 100
PARAMETER num_ctx 28000

# The SYSTEM instruction sets a system-level prompt to define the model's behavior or persona.
# SYSTEM "You are a helpful AI assistant. Your role is to provide clear and concise answers."

# The TEMPLATE instruction defines the full prompt template.
# If not specified, a default template is used.
# {{ .System }} is replaced by the SYSTEM message.
# {{ .Prompt }} is replaced by the user's input.
# TEMPLATE """
# {{ if .System }}<|start_header_id|>system<|end_header_id|>
# 
# {{ .System }}<|eot_id|>{{ end }}{{ if .Prompt }}<|start_header_id|>user<|end_header_id|>
# 
# {{ .Prompt }}<|eot_id|>{{ end }}<|start_header_id|>assistant<|end_header_id|>
# 
# {{ .Response }}<|eot_id|>
# """

# Other optional instructions include ADAPTER for LoRA adapters and LICENSE for the model's license.
# ADAPTER ./my-adapter
# LICENSE "Your license text here"
